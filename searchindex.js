Search.setIndex({"docnames": ["cli_usage", "compressai_vision/codecs", "compressai_vision/datasets", "compressai_vision/evaluators", "compressai_vision/model_wrappers", "compressai_vision/pipelines/index", "compressai_vision/pipelines/remote_inference", "compressai_vision/pipelines/split_inference", "compressai_vision/registry", "docker", "index", "installation"], "filenames": ["cli_usage.rst", "compressai_vision/codecs.rst", "compressai_vision/datasets.rst", "compressai_vision/evaluators.rst", "compressai_vision/model_wrappers.rst", "compressai_vision/pipelines/index.rst", "compressai_vision/pipelines/remote_inference.rst", "compressai_vision/pipelines/split_inference.rst", "compressai_vision/registry.rst", "docker.rst", "index.rst", "installation.rst"], "titles": ["Command line usage", "compressai_vision.codecs", "compressai_vision.datasets", "compressai_vision.evaluators", "compressai_vision.model_wrappers", "compressai_vision.pipelines", "compressai_vision.pipelines.remote_inference", "compressai_vision.pipelines.split_inference", "compressai_vision.registry", "Docker", "CompressAI-Vision", "Installation"], "terms": {"run": [0, 9, 11], "evalu": [0, 8, 10], "To": [0, 9, 10], "compress": [0, 10], "accuraci": [0, 4], "perform": [0, 1, 3], "pleas": [0, 9, 10, 11], "follow": [0, 10, 11], "compressai": [0, 3, 9, 11], "config": [0, 6, 7], "path": [0, 1, 3], "cfg": [0, 4], "eval_split_inference_exampl": 0, "check": [0, 1], "script": [0, 9, 11], "provid": [0, 9], "exampl": 0, "support": [0, 2, 9, 10], "codec": [0, 8, 10], "dataset": [0, 1, 3, 8, 10], "eval_remote_inference_exampl": 0, "class": [1, 2, 3, 4, 6, 7, 8], "bypass": 1, "kwarg": [1, 2, 4], "sourc": [1, 2, 3, 4, 6, 7, 8, 11], "doe": [1, 2], "encod": 1, "decod": 1, "whatsoev": 1, "us": [1, 9, 10, 11], "debug": 1, "input": [1, 4], "dict": [1, 4, 6, 7], "codec_output_dir": 1, "str": [1, 2, 3, 4, 6, 8], "file_prefix": 1, "org_img_s": 1, "none": [1, 3], "remote_infer": 1, "fals": 1, "vcm_mode": 1, "bitstream_nam": 1, "return": [1, 2], "calcul": 1, "its": 1, "raw": 1, "size": [1, 4], "properti": [1, 2, 4], "eval_encode_typ": 1, "qp_valu": 1, "train": [1, 2, 3, 4, 6, 7], "bool": [1, 2, 3, 4, 6, 7], "hm": [1, 11], "vision_model": 1, "basewrapp": [1, 4], "hevc": 1, "refer": [1, 3, 10, 11], "softwar": [1, 9, 11], "get_encode_cmd": 1, "inp_yuv_path": 1, "qp": 1, "int": 1, "bitstream_path": 1, "width": 1, "height": 1, "nb_frame": 1, "1": [1, 9], "parallel_encod": 1, "hash_check": 1, "0": [1, 9], "chroma_format": 1, "400": 1, "input_bitdepth": 1, "10": 1, "output_bitdepth": 1, "list": [1, 6, 7, 9], "ani": [1, 2], "gener": 1, "command": 1, "video": [1, 10], "specifi": 1, "paramet": 1, "param": 1, "The": [1, 3, 9, 10, 11], "yuv": 1, "file": [1, 10], "type": 1, "quantiz": 1, "output": 1, "bitstream": 1, "number": 1, "frame": [1, 4], "default": [1, 9], "option": [1, 2], "whether": 1, "enabl": 1, "parallel": 1, "hash": 1, "valu": 1, "chroma": 1, "format": 1, "bitdepth": 1, "line": 1, "sic_sfu2022": 1, "devic": [1, 4, 6, 7], "x": [1, 4], "static": [1, 3], "get_padded_input_s": 1, "fsize": 1, "p": 1, "load_pretrain": 1, "model": [1, 3, 4, 8, 10], "filenam": 1, "reset": [1, 3, 4], "update_model": 1, "loaded_st": 1, "vtm": [1, 9, 11], "vvc": 1, "close_bitstream_fil": 1, "featur": [1, 4, 10], "directori": [1, 2, 9], "store": [1, 2], "prefix": 1, "origin": 1, "imag": [1, 2, 4, 9], "remot": 1, "infer": 1, "pipelin": [1, 3, 8, 9, 10], "i": [1, 2, 3, 10, 11], "dictionari": 1, "data": [1, 2], "where": 1, "save": 1, "name": [1, 3, 8], "ad": [1, 10], "indic": 1, "done": 1, "A": [1, 3], "contain": [1, 9], "byte": 1, "per": 1, "get_check_list_of_path": 1, "get_decode_cmd": 1, "yuv_dec_path": 1, "get": [1, 10], "an": [1, 2, 4, 8, 9], "extern": 1, "argument": 1, "bit": 1, "depth": 1, "get_io_buffer_cont": 1, "get_parcat_cmd": 1, "tupl": [1, 6, 7], "need": [1, 9, 11], "concaten": 1, "folder": [1, 2], "open_bitstream_fil": 1, "mode": [1, 4], "rb": 1, "vvenc": [1, 11], "dataset_nam": [1, 2, 3], "vvdec": 1, "process": [1, 4], "string": [1, 2, 8], "repres": 1, "x264": 1, "x265": 1, "extract": 1, "from": [1, 4, 11], "tensor": 1, "flag": 1, "ffmpeg": [1, 9], "lib": 1, "given": [1, 8], "frmrate": 1, "h": [1, 10], "264": 1, "rate": 1, "265": 1, "datacatalog": 2, "root": 2, "imgs_fold": 2, "annotation_fil": 2, "sampl": 2, "json": 2, "seqinfo": 2, "ini": 2, "sample_dataset": 2, "ext": 2, "png": 2, "annotation_path": 2, "imgs_folder_path": 2, "seqinfo_path": 2, "defaultdataset": 2, "valid": 2, "load": 2, "databas": 2, "test": [2, 10], "ar": [2, 9, 11], "respect": [2, 11], "separ": 2, "current": 2, "thi": [2, 3, 4, 8, 9, 10, 11], "relat": 2, "oper": 2, "rootdir": 2, "img000": 2, "img001": 2, "variabl": 2, "transform": 2, "callabl": 2, "function": [2, 3], "take": [2, 9, 11], "pil": 2, "version": [2, 11], "use_bgr": 2, "true": 2, "color": 2, "order": [2, 9], "bgr": 2, "otherwis": 2, "rgb": 2, "detectron2dataset": 2, "get_org_mapper_func": 2, "trackingdataset": 2, "deccode_compressed_rl": 2, "get_seq_info": 2, "seq_info_path": 2, "baseevalu": 3, "datacatalog_nam": 3, "output_dir": 3, "vision_output": 3, "criteria": 3, "digest": 3, "gt": 3, "pred": 3, "get_coco_eval_info_nam": 3, "get_jde_eval_info_nam": 3, "result": 3, "save_path": 3, "set_annotation_info": 3, "write_result": 3, "out": 3, "cocoev": 3, "ap": 3, "mot_hieve_ev": 3, "mota": 3, "multipl": 3, "object": [3, 8], "track": 3, "hiev": [3, 10], "mot": 3, "jde": [3, 9], "specif": 3, "mot_ev": 3, "mot_jde_ev": 3, "vision": [3, 8, 9, 11], "inherit": 3, "interfac": [3, 4], "architectur": 3, "below": 3, "inin": 3, "toward": 3, "realtim": 3, "util": 3, "py": 3, "zhongdao": 3, "full": [3, 4], "licens": 3, "statement": 3, "can": [3, 4, 9], "found": 3, "digest_summari": 3, "summari": 3, "mot_tvd_ev": 3, "tvd": 3, "openimageschallengeev": 3, "ap50": 3, "visualqualityev": 3, "psnr": 3, "compute_msssim": 3, "b": 3, "compute_psnr": 3, "yoloxcocoev": 3, "note": 4, "virtual": 4, "build": [4, 9, 11], "your": [4, 9], "wrapper": 4, "instanc": 4, "help": [4, 10], "you": [4, 9, 10, 11], "wrap": 4, "off": 4, "shelf": 4, "so": 4, "behav": 4, "variou": 4, "partial": 4, "deeper_features_for_accuracy_proxi": 4, "comput": 4, "proxi": 4, "deeper": 4, "layer": 4, "than": 4, "nn": [4, 10], "part1": 4, "features_to_output": 4, "complet": 4, "downstream": 4, "task": [4, 8, 10], "intermedi": 4, "deep": 4, "forward": 4, "input_map_funct": 4, "end": 4, "manner": 4, "all": [4, 9], "wai": 4, "input_to_featur": 4, "": 4, "model_cfg_path": 4, "pretrained_weight_path": 4, "faster_rcnn_r_50_fpn_3x": 4, "faster_rcnn_x_101_32x8d_fpn_3x": 4, "jde_1088x608": 4, "get_input_s": 4, "network": [4, 10], "mask_rcnn_r_50_fpn_3x": 4, "mask_rcnn_x_101_32x8d_fpn_3x": 4, "yolox_darknet53": 4, "split_l13": 4, "split_l37": 4, "enable_squeeze_at_split": 4, "split_id": 4, "imageremoteinfer": 6, "videoremoteinfer": 6, "build_input_list": [6, 7], "dataload": [6, 7], "imagesplitinfer": 7, "videosplitinfer": 7, "regist": 8, "etc": [8, 9], "make": 8, "them": 8, "access": 8, "via": [8, 11], "dynam": 8, "yaml": 8, "configur": 8, "map": 8, "concret": 8, "creation": 8, "method": [8, 10], "allow": 8, "u": [8, 11], "creat": [8, 9, 11], "depend": 8, "runtim": 8, "register_codec": 8, "decor": 8, "register_datacatalog": 8, "register_dataset": 8, "register_evalu": 8, "register_multask_codec": 8, "multi": 8, "register_pipelin": 8, "register_vision_model": 8, "warn": 9, "moment": 9, "up": 9, "date": 9, "correct": 9, "stack": [9, 11], "For": 9, "fcm": [9, 10], "pytorch": [9, 11], "detectron2": [9, 11], "vcm": [9, 10], "fiftyon": 9, "librari": [9, 11], "look": 9, "find": 9, "each": 9, "case": 9, "driver": 9, "bash": [9, 11], "onc": 9, "abl": 9, "nvidia": 9, "gpu": 9, "dockerfil": 9, "make_imag": 9, "helper": 9, "run_imag": 9, "compressai_vis": 9, "just": 9, "should": 9, "own": 9, "copi": 9, "suit": 9, "interact": 9, "notebook": 9, "bind": 9, "mount": 9, "local": 9, "batch": 9, "job": 9, "demo": 9, "start": [9, 10], "python": 9, "tensorboard": 9, "cuda": 9, "o": 9, "descript": 9, "2": 9, "11": 9, "3": 9, "12": 9, "4": 9, "7": 9, "ubuntu": [9, 11], "20": [9, 11], "04": [9, 11], "inclus": 9, "8": [9, 11], "hot": 9, "reload": 9, "develop": [9, 10], "standard": 10, "context": 10, "code": [10, 11], "machin": 10, "e": [10, 11], "optim": 10, "algorithm": 10, "neural": 10, "base": 10, "detector": 10, "goal": 10, "platform": 10, "compar": 10, "now": 10, "common": 10, "condit": 10, "defin": [10, 11], "iso": 10, "mpeg": 10, "hoc": 10, "group": 10, "includ": 10, "openimagev6": 10, "subset": 10, "sfu": 10, "tencent": 10, "protocol": 10, "coco": 10, "anchor": 10, "state": 10, "art": 10, "266": 10, "vcc": 10, "document": 10, "site": 10, "reconstruct": 10, "also": 10, "readm": [10, 11], "within": [10, 11], "go": 10, "through": 10, "instal": 10, "step": 10, "section": 11, "explain": 11, "how": 11, "requir": 11, "nativ": 11, "system": 11, "howev": 11, "might": 11, "prefer": 11, "docker": 11, "instead": 11, "here": 11, "we": 11, "assum": 11, "lt": 11, "newer": 11, "first": 11, "activ": 11, "virtualenv": 11, "python3": 11, "m": 11, "venv": 11, "bin": 11, "pip": 11, "want": 11, "explicitli": 11, "while": 11, "sh": 11, "after": 11, "deactiv": 11, "effect": 11, "place": 11, "binari": 11, "clone": 11, "select": 11, "repo": 11, "link": 11, "desir": 11, "tag": 11, "http": 11, "vcgit": 11, "hhi": 11, "fraunhof": 11, "de": 11, "jvet": 11, "vvcsoftware_vtm": 11, "fraunhoferhhi": 11, "launch": 11}, "objects": {"compressai_vision": [[1, 0, 0, "-", "codecs"], [2, 0, 0, "-", "datasets"], [3, 0, 0, "-", "evaluators"], [4, 0, 0, "-", "model_wrappers"], [8, 0, 0, "-", "registry"]], "compressai_vision.codecs": [[1, 1, 1, "", "Bypass"], [1, 1, 1, "", "HM"], [1, 1, 1, "", "SIC_SFU2022"], [1, 1, 1, "", "VTM"], [1, 1, 1, "", "VVENC"], [1, 1, 1, "", "x264"], [1, 1, 1, "", "x265"]], "compressai_vision.codecs.Bypass": [[1, 2, 1, "", "decode"], [1, 2, 1, "", "encode"], [1, 3, 1, "", "eval_encode_type"], [1, 3, 1, "", "qp_value"], [1, 4, 1, "", "training"]], "compressai_vision.codecs.HM": [[1, 2, 1, "", "get_encode_cmd"], [1, 4, 1, "", "training"]], "compressai_vision.codecs.SIC_SFU2022": [[1, 2, 1, "", "decode"], [1, 2, 1, "", "encode"], [1, 3, 1, "", "eval_encode_type"], [1, 2, 1, "", "get_padded_input_size"], [1, 2, 1, "", "load_pretrained"], [1, 3, 1, "", "qp_value"], [1, 2, 1, "", "reset"], [1, 2, 1, "", "update_model"]], "compressai_vision.codecs.VTM": [[1, 2, 1, "", "close_bitstream_file"], [1, 2, 1, "", "decode"], [1, 2, 1, "", "encode"], [1, 3, 1, "", "eval_encode_type"], [1, 2, 1, "", "get_check_list_of_paths"], [1, 2, 1, "", "get_decode_cmd"], [1, 2, 1, "", "get_encode_cmd"], [1, 2, 1, "", "get_io_buffer_contents"], [1, 2, 1, "", "get_parcat_cmd"], [1, 2, 1, "", "open_bitstream_file"], [1, 3, 1, "", "qp_value"], [1, 2, 1, "", "reset"], [1, 4, 1, "", "training"]], "compressai_vision.codecs.VVENC": [[1, 2, 1, "", "get_encode_cmd"], [1, 4, 1, "", "training"]], "compressai_vision.codecs.x264": [[1, 2, 1, "", "decode"], [1, 2, 1, "", "encode"], [1, 3, 1, "", "eval_encode_type"], [1, 2, 1, "", "get_decode_cmd"], [1, 2, 1, "", "get_encode_cmd"], [1, 3, 1, "", "qp_value"], [1, 4, 1, "", "training"]], "compressai_vision.codecs.x265": [[1, 2, 1, "", "get_encode_cmd"], [1, 4, 1, "", "training"]], "compressai_vision.datasets": [[2, 1, 1, "", "DataCatalog"], [2, 1, 1, "", "DefaultDataset"], [2, 1, 1, "", "Detectron2Dataset"], [2, 1, 1, "", "TrackingDataset"], [2, 5, 1, "", "deccode_compressed_rle"], [2, 5, 1, "", "get_seq_info"]], "compressai_vision.datasets.DataCatalog": [[2, 3, 1, "", "annotation_path"], [2, 3, 1, "", "dataset"], [2, 3, 1, "", "dataset_name"], [2, 3, 1, "", "imgs_folder_path"], [2, 3, 1, "", "seqinfo_path"]], "compressai_vision.datasets.Detectron2Dataset": [[2, 2, 1, "", "get_org_mapper_func"]], "compressai_vision.datasets.TrackingDataset": [[2, 2, 1, "", "get_org_mapper_func"]], "compressai_vision.evaluators": [[3, 1, 1, "", "BaseEvaluator"], [3, 1, 1, "", "COCOEVal"], [3, 1, 1, "", "MOT_HiEve_Eval"], [3, 1, 1, "", "MOT_JDE_Eval"], [3, 1, 1, "", "MOT_TVD_Eval"], [3, 1, 1, "", "OpenImagesChallengeEval"], [3, 1, 1, "", "VisualQualityEval"], [3, 1, 1, "", "YOLOXCOCOEval"]], "compressai_vision.evaluators.BaseEvaluator": [[3, 2, 1, "", "digest"], [3, 2, 1, "", "get_coco_eval_info_name"], [3, 2, 1, "", "get_jde_eval_info_name"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 2, 1, "", "set_annotation_info"], [3, 4, 1, "", "training"], [3, 2, 1, "", "write_results"]], "compressai_vision.evaluators.COCOEVal": [[3, 2, 1, "", "digest"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 4, 1, "", "training"]], "compressai_vision.evaluators.MOT_HiEve_Eval": [[3, 2, 1, "", "mot_eval"], [3, 4, 1, "", "training"]], "compressai_vision.evaluators.MOT_JDE_Eval": [[3, 2, 1, "", "digest"], [3, 2, 1, "", "digest_summary"], [3, 2, 1, "", "mot_eval"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 4, 1, "", "training"]], "compressai_vision.evaluators.MOT_TVD_Eval": [[3, 2, 1, "", "mot_eval"], [3, 4, 1, "", "training"]], "compressai_vision.evaluators.OpenImagesChallengeEval": [[3, 2, 1, "", "digest"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 4, 1, "", "training"]], "compressai_vision.evaluators.VisualQualityEval": [[3, 2, 1, "", "compute_msssim"], [3, 2, 1, "", "compute_psnr"], [3, 2, 1, "", "digest"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 4, 1, "", "training"], [3, 2, 1, "", "write_results"]], "compressai_vision.evaluators.YOLOXCOCOEval": [[3, 2, 1, "", "digest"], [3, 2, 1, "", "reset"], [3, 2, 1, "", "results"], [3, 4, 1, "", "training"]], "compressai_vision.model_wrappers": [[4, 1, 1, "", "BaseWrapper"], [4, 1, 1, "", "faster_rcnn_R_50_FPN_3x"], [4, 1, 1, "", "faster_rcnn_X_101_32x8d_FPN_3x"], [4, 1, 1, "", "jde_1088x608"], [4, 1, 1, "", "mask_rcnn_R_50_FPN_3x"], [4, 1, 1, "", "mask_rcnn_X_101_32x8d_FPN_3x"], [4, 1, 1, "", "yolox_darknet53"]], "compressai_vision.model_wrappers.BaseWrapper": [[4, 3, 1, "", "cfg"], [4, 2, 1, "", "deeper_features_for_accuracy_proxy"], [4, 2, 1, "", "features_to_output"], [4, 2, 1, "", "forward"], [4, 2, 1, "", "input_to_features"], [4, 3, 1, "", "model_cfg_path"], [4, 3, 1, "", "pretrained_weight_path"], [4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.faster_rcnn_R_50_FPN_3x": [[4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.faster_rcnn_X_101_32x8d_FPN_3x": [[4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.jde_1088x608": [[4, 2, 1, "", "deeper_features_for_accuracy_proxy"], [4, 2, 1, "", "features_to_output"], [4, 2, 1, "", "forward"], [4, 2, 1, "", "get_input_size"], [4, 2, 1, "", "input_to_features"], [4, 2, 1, "", "reset"], [4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.mask_rcnn_R_50_FPN_3x": [[4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.mask_rcnn_X_101_32x8d_FPN_3x": [[4, 4, 1, "", "training"]], "compressai_vision.model_wrappers.yolox_darknet53": [[4, 3, 1, "", "SPLIT_L13"], [4, 3, 1, "", "SPLIT_L37"], [4, 2, 1, "", "enable_squeeze_at_split"], [4, 2, 1, "", "features_to_output"], [4, 2, 1, "", "forward"], [4, 2, 1, "", "input_to_features"], [4, 4, 1, "", "training"]], "compressai_vision.pipelines": [[6, 0, 0, "-", "remote_inference"], [7, 0, 0, "-", "split_inference"]], "compressai_vision.pipelines.remote_inference": [[6, 1, 1, "", "ImageRemoteInference"], [6, 1, 1, "", "VideoRemoteInference"]], "compressai_vision.pipelines.remote_inference.ImageRemoteInference": [[6, 4, 1, "", "training"]], "compressai_vision.pipelines.remote_inference.VideoRemoteInference": [[6, 2, 1, "", "build_input_lists"], [6, 4, 1, "", "training"]], "compressai_vision.pipelines.split_inference": [[7, 1, 1, "", "ImageSplitInference"], [7, 1, 1, "", "VideoSplitInference"]], "compressai_vision.pipelines.split_inference.ImageSplitInference": [[7, 4, 1, "", "training"]], "compressai_vision.pipelines.split_inference.VideoSplitInference": [[7, 2, 1, "", "build_input_lists"], [7, 4, 1, "", "training"]], "compressai_vision.registry": [[8, 0, 0, "-", "registry"]], "compressai_vision.registry.registry": [[8, 5, 1, "", "register_codec"], [8, 5, 1, "", "register_datacatalog"], [8, 5, 1, "", "register_dataset"], [8, 5, 1, "", "register_evaluator"], [8, 5, 1, "", "register_multask_codec"], [8, 5, 1, "", "register_pipeline"], [8, 5, 1, "", "register_vision_model"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"command": 0, "line": 0, "usag": 0, "split": 0, "infer": 0, "pipelin": [0, 5, 6, 7, 11], "remot": 0, "compressai_vis": [1, 2, 3, 4, 5, 6, 7, 8], "codec": [1, 11], "dataset": 2, "evalu": 3, "model_wrapp": 4, "remote_infer": 6, "split_infer": 7, "registri": 8, "docker": 9, "file": 9, "version": 9, "compressai": 10, "vision": 10, "instal": 11, "1": 11, "python": 11, "depend": 11, "2": 11, "If": 11, "your": 11, "includ": 11, "tradit": 11}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Command line usage": [[0, "command-line-usage"]], "Split inference pipelines": [[0, "split-inference-pipelines"]], "Remote inference pipelines": [[0, "remote-inference-pipelines"]], "compressai_vision.codecs": [[1, "module-compressai_vision.codecs"]], "compressai_vision.datasets": [[2, "module-compressai_vision.datasets"]], "compressai_vision.evaluators": [[3, "module-compressai_vision.evaluators"]], "compressai_vision.model_wrappers": [[4, "module-compressai_vision.model_wrappers"]], "compressai_vision.pipelines": [[5, "compressai-vision-pipelines"]], "compressai_vision.pipelines.remote_inference": [[6, "module-compressai_vision.pipelines.remote_inference"]], "compressai_vision.pipelines.split_inference": [[7, "module-compressai_vision.pipelines.split_inference"]], "compressai_vision.registry": [[8, "compressai-vision-registry"]], "registry": [[8, "module-compressai_vision.registry.registry"]], "Docker": [[9, "docker"]], "File versions": [[9, "file-versions"]], "CompressAI-Vision": [[10, "compressai-vision"]], "Installation": [[11, "installation"]], "1. Python dependencies": [[11, "python-dependencies"]], "2. If your pipeline includes traditional codecs": [[11, "if-your-pipeline-includes-traditional-codecs"]]}, "indexentries": {"bypass (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.Bypass"]], "hm (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.HM"]], "sic_sfu2022 (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.SIC_SFU2022"]], "vtm (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.VTM"]], "vvenc (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.VVENC"]], "close_bitstream_file() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.close_bitstream_file"]], "compressai_vision.codecs": [[1, "module-compressai_vision.codecs"]], "decode() (compressai_vision.codecs.bypass method)": [[1, "compressai_vision.codecs.Bypass.decode"]], "decode() (compressai_vision.codecs.sic_sfu2022 method)": [[1, "compressai_vision.codecs.SIC_SFU2022.decode"]], "decode() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.decode"]], "decode() (compressai_vision.codecs.x264 method)": [[1, "compressai_vision.codecs.x264.decode"]], "encode() (compressai_vision.codecs.bypass method)": [[1, "compressai_vision.codecs.Bypass.encode"]], "encode() (compressai_vision.codecs.sic_sfu2022 method)": [[1, "compressai_vision.codecs.SIC_SFU2022.encode"]], "encode() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.encode"]], "encode() (compressai_vision.codecs.x264 method)": [[1, "compressai_vision.codecs.x264.encode"]], "eval_encode_type (compressai_vision.codecs.bypass property)": [[1, "compressai_vision.codecs.Bypass.eval_encode_type"]], "eval_encode_type (compressai_vision.codecs.sic_sfu2022 property)": [[1, "compressai_vision.codecs.SIC_SFU2022.eval_encode_type"]], "eval_encode_type (compressai_vision.codecs.vtm property)": [[1, "compressai_vision.codecs.VTM.eval_encode_type"]], "eval_encode_type (compressai_vision.codecs.x264 property)": [[1, "compressai_vision.codecs.x264.eval_encode_type"]], "get_check_list_of_paths() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.get_check_list_of_paths"]], "get_decode_cmd() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.get_decode_cmd"]], "get_decode_cmd() (compressai_vision.codecs.x264 method)": [[1, "compressai_vision.codecs.x264.get_decode_cmd"]], "get_encode_cmd() (compressai_vision.codecs.hm method)": [[1, "compressai_vision.codecs.HM.get_encode_cmd"]], "get_encode_cmd() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.get_encode_cmd"]], "get_encode_cmd() (compressai_vision.codecs.vvenc method)": [[1, "compressai_vision.codecs.VVENC.get_encode_cmd"]], "get_encode_cmd() (compressai_vision.codecs.x264 method)": [[1, "compressai_vision.codecs.x264.get_encode_cmd"]], "get_encode_cmd() (compressai_vision.codecs.x265 method)": [[1, "compressai_vision.codecs.x265.get_encode_cmd"]], "get_io_buffer_contents() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.get_io_buffer_contents"]], "get_padded_input_size() (compressai_vision.codecs.sic_sfu2022 static method)": [[1, "compressai_vision.codecs.SIC_SFU2022.get_padded_input_size"]], "get_parcat_cmd() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.get_parcat_cmd"]], "load_pretrained() (compressai_vision.codecs.sic_sfu2022 static method)": [[1, "compressai_vision.codecs.SIC_SFU2022.load_pretrained"]], "module": [[1, "module-compressai_vision.codecs"], [2, "module-compressai_vision.datasets"], [3, "module-compressai_vision.evaluators"], [4, "module-compressai_vision.model_wrappers"], [6, "module-compressai_vision.pipelines.remote_inference"], [7, "module-compressai_vision.pipelines.split_inference"], [8, "module-compressai_vision.registry"], [8, "module-compressai_vision.registry.registry"]], "open_bitstream_file() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.open_bitstream_file"]], "qp_value (compressai_vision.codecs.bypass property)": [[1, "compressai_vision.codecs.Bypass.qp_value"]], "qp_value (compressai_vision.codecs.sic_sfu2022 property)": [[1, "compressai_vision.codecs.SIC_SFU2022.qp_value"]], "qp_value (compressai_vision.codecs.vtm property)": [[1, "compressai_vision.codecs.VTM.qp_value"]], "qp_value (compressai_vision.codecs.x264 property)": [[1, "compressai_vision.codecs.x264.qp_value"]], "reset() (compressai_vision.codecs.sic_sfu2022 method)": [[1, "compressai_vision.codecs.SIC_SFU2022.reset"]], "reset() (compressai_vision.codecs.vtm method)": [[1, "compressai_vision.codecs.VTM.reset"]], "training (compressai_vision.codecs.bypass attribute)": [[1, "compressai_vision.codecs.Bypass.training"]], "training (compressai_vision.codecs.hm attribute)": [[1, "compressai_vision.codecs.HM.training"]], "training (compressai_vision.codecs.vtm attribute)": [[1, "compressai_vision.codecs.VTM.training"]], "training (compressai_vision.codecs.vvenc attribute)": [[1, "compressai_vision.codecs.VVENC.training"]], "training (compressai_vision.codecs.x264 attribute)": [[1, "compressai_vision.codecs.x264.training"]], "training (compressai_vision.codecs.x265 attribute)": [[1, "compressai_vision.codecs.x265.training"]], "update_model() (compressai_vision.codecs.sic_sfu2022 static method)": [[1, "compressai_vision.codecs.SIC_SFU2022.update_model"]], "x264 (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.x264"]], "x265 (class in compressai_vision.codecs)": [[1, "compressai_vision.codecs.x265"]], "datacatalog (class in compressai_vision.datasets)": [[2, "compressai_vision.datasets.DataCatalog"]], "defaultdataset (class in compressai_vision.datasets)": [[2, "compressai_vision.datasets.DefaultDataset"]], "detectron2dataset (class in compressai_vision.datasets)": [[2, "compressai_vision.datasets.Detectron2Dataset"]], "trackingdataset (class in compressai_vision.datasets)": [[2, "compressai_vision.datasets.TrackingDataset"]], "annotation_path (compressai_vision.datasets.datacatalog property)": [[2, "compressai_vision.datasets.DataCatalog.annotation_path"]], "compressai_vision.datasets": [[2, "module-compressai_vision.datasets"]], "dataset (compressai_vision.datasets.datacatalog property)": [[2, "compressai_vision.datasets.DataCatalog.dataset"]], "dataset_name (compressai_vision.datasets.datacatalog property)": [[2, "compressai_vision.datasets.DataCatalog.dataset_name"]], "deccode_compressed_rle() (in module compressai_vision.datasets)": [[2, "compressai_vision.datasets.deccode_compressed_rle"]], "get_org_mapper_func() (compressai_vision.datasets.detectron2dataset method)": [[2, "compressai_vision.datasets.Detectron2Dataset.get_org_mapper_func"]], "get_org_mapper_func() (compressai_vision.datasets.trackingdataset method)": [[2, "compressai_vision.datasets.TrackingDataset.get_org_mapper_func"]], "get_seq_info() (in module compressai_vision.datasets)": [[2, "compressai_vision.datasets.get_seq_info"]], "imgs_folder_path (compressai_vision.datasets.datacatalog property)": [[2, "compressai_vision.datasets.DataCatalog.imgs_folder_path"]], "seqinfo_path (compressai_vision.datasets.datacatalog property)": [[2, "compressai_vision.datasets.DataCatalog.seqinfo_path"]], "baseevaluator (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.BaseEvaluator"]], "cocoeval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.COCOEVal"]], "mot_hieve_eval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.MOT_HiEve_Eval"]], "mot_jde_eval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval"]], "mot_tvd_eval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.MOT_TVD_Eval"]], "openimageschallengeeval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.OpenImagesChallengeEval"]], "visualqualityeval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.VisualQualityEval"]], "yoloxcocoeval (class in compressai_vision.evaluators)": [[3, "compressai_vision.evaluators.YOLOXCOCOEval"]], "compressai_vision.evaluators": [[3, "module-compressai_vision.evaluators"]], "compute_msssim() (compressai_vision.evaluators.visualqualityeval static method)": [[3, "compressai_vision.evaluators.VisualQualityEval.compute_msssim"]], "compute_psnr() (compressai_vision.evaluators.visualqualityeval static method)": [[3, "compressai_vision.evaluators.VisualQualityEval.compute_psnr"]], "digest() (compressai_vision.evaluators.baseevaluator method)": [[3, "compressai_vision.evaluators.BaseEvaluator.digest"]], "digest() (compressai_vision.evaluators.cocoeval method)": [[3, "compressai_vision.evaluators.COCOEVal.digest"]], "digest() (compressai_vision.evaluators.mot_jde_eval method)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.digest"]], "digest() (compressai_vision.evaluators.openimageschallengeeval method)": [[3, "compressai_vision.evaluators.OpenImagesChallengeEval.digest"]], "digest() (compressai_vision.evaluators.visualqualityeval method)": [[3, "compressai_vision.evaluators.VisualQualityEval.digest"]], "digest() (compressai_vision.evaluators.yoloxcocoeval method)": [[3, "compressai_vision.evaluators.YOLOXCOCOEval.digest"]], "digest_summary() (compressai_vision.evaluators.mot_jde_eval static method)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.digest_summary"]], "get_coco_eval_info_name() (compressai_vision.evaluators.baseevaluator static method)": [[3, "compressai_vision.evaluators.BaseEvaluator.get_coco_eval_info_name"]], "get_jde_eval_info_name() (compressai_vision.evaluators.baseevaluator static method)": [[3, "compressai_vision.evaluators.BaseEvaluator.get_jde_eval_info_name"]], "mot_eval() (compressai_vision.evaluators.mot_hieve_eval method)": [[3, "compressai_vision.evaluators.MOT_HiEve_Eval.mot_eval"]], "mot_eval() (compressai_vision.evaluators.mot_jde_eval method)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.mot_eval"]], "mot_eval() (compressai_vision.evaluators.mot_tvd_eval method)": [[3, "compressai_vision.evaluators.MOT_TVD_Eval.mot_eval"]], "reset() (compressai_vision.evaluators.baseevaluator method)": [[3, "compressai_vision.evaluators.BaseEvaluator.reset"]], "reset() (compressai_vision.evaluators.cocoeval method)": [[3, "compressai_vision.evaluators.COCOEVal.reset"]], "reset() (compressai_vision.evaluators.mot_jde_eval method)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.reset"]], "reset() (compressai_vision.evaluators.openimageschallengeeval method)": [[3, "compressai_vision.evaluators.OpenImagesChallengeEval.reset"]], "reset() (compressai_vision.evaluators.visualqualityeval method)": [[3, "compressai_vision.evaluators.VisualQualityEval.reset"]], "reset() (compressai_vision.evaluators.yoloxcocoeval method)": [[3, "compressai_vision.evaluators.YOLOXCOCOEval.reset"]], "results() (compressai_vision.evaluators.baseevaluator method)": [[3, "compressai_vision.evaluators.BaseEvaluator.results"]], "results() (compressai_vision.evaluators.cocoeval method)": [[3, "compressai_vision.evaluators.COCOEVal.results"]], "results() (compressai_vision.evaluators.mot_jde_eval method)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.results"]], "results() (compressai_vision.evaluators.openimageschallengeeval method)": [[3, "compressai_vision.evaluators.OpenImagesChallengeEval.results"]], "results() (compressai_vision.evaluators.visualqualityeval method)": [[3, "compressai_vision.evaluators.VisualQualityEval.results"]], "results() (compressai_vision.evaluators.yoloxcocoeval method)": [[3, "compressai_vision.evaluators.YOLOXCOCOEval.results"]], "set_annotation_info() (compressai_vision.evaluators.baseevaluator method)": [[3, "compressai_vision.evaluators.BaseEvaluator.set_annotation_info"]], "training (compressai_vision.evaluators.baseevaluator attribute)": [[3, "compressai_vision.evaluators.BaseEvaluator.training"]], "training (compressai_vision.evaluators.cocoeval attribute)": [[3, "compressai_vision.evaluators.COCOEVal.training"]], "training (compressai_vision.evaluators.mot_hieve_eval attribute)": [[3, "compressai_vision.evaluators.MOT_HiEve_Eval.training"]], "training (compressai_vision.evaluators.mot_jde_eval attribute)": [[3, "compressai_vision.evaluators.MOT_JDE_Eval.training"]], "training (compressai_vision.evaluators.mot_tvd_eval attribute)": [[3, "compressai_vision.evaluators.MOT_TVD_Eval.training"]], "training (compressai_vision.evaluators.openimageschallengeeval attribute)": [[3, "compressai_vision.evaluators.OpenImagesChallengeEval.training"]], "training (compressai_vision.evaluators.visualqualityeval attribute)": [[3, "compressai_vision.evaluators.VisualQualityEval.training"]], "training (compressai_vision.evaluators.yoloxcocoeval attribute)": [[3, "compressai_vision.evaluators.YOLOXCOCOEval.training"]], "write_results() (compressai_vision.evaluators.baseevaluator method)": [[3, "compressai_vision.evaluators.BaseEvaluator.write_results"]], "write_results() (compressai_vision.evaluators.visualqualityeval method)": [[3, "compressai_vision.evaluators.VisualQualityEval.write_results"]], "basewrapper (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.BaseWrapper"]], "split_l13 (compressai_vision.model_wrappers.yolox_darknet53 property)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.SPLIT_L13"]], "split_l37 (compressai_vision.model_wrappers.yolox_darknet53 property)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.SPLIT_L37"]], "cfg (compressai_vision.model_wrappers.basewrapper property)": [[4, "compressai_vision.model_wrappers.BaseWrapper.cfg"]], "compressai_vision.model_wrappers": [[4, "module-compressai_vision.model_wrappers"]], "deeper_features_for_accuracy_proxy() (compressai_vision.model_wrappers.basewrapper method)": [[4, "compressai_vision.model_wrappers.BaseWrapper.deeper_features_for_accuracy_proxy"]], "deeper_features_for_accuracy_proxy() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.deeper_features_for_accuracy_proxy"]], "enable_squeeze_at_split() (compressai_vision.model_wrappers.yolox_darknet53 method)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.enable_squeeze_at_split"]], "faster_rcnn_r_50_fpn_3x (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.faster_rcnn_R_50_FPN_3x"]], "faster_rcnn_x_101_32x8d_fpn_3x (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.faster_rcnn_X_101_32x8d_FPN_3x"]], "features_to_output() (compressai_vision.model_wrappers.basewrapper method)": [[4, "compressai_vision.model_wrappers.BaseWrapper.features_to_output"]], "features_to_output() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.features_to_output"]], "features_to_output() (compressai_vision.model_wrappers.yolox_darknet53 method)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.features_to_output"]], "forward() (compressai_vision.model_wrappers.basewrapper method)": [[4, "compressai_vision.model_wrappers.BaseWrapper.forward"]], "forward() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.forward"]], "forward() (compressai_vision.model_wrappers.yolox_darknet53 method)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.forward"]], "get_input_size() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.get_input_size"]], "input_to_features() (compressai_vision.model_wrappers.basewrapper method)": [[4, "compressai_vision.model_wrappers.BaseWrapper.input_to_features"]], "input_to_features() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.input_to_features"]], "input_to_features() (compressai_vision.model_wrappers.yolox_darknet53 method)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.input_to_features"]], "jde_1088x608 (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.jde_1088x608"]], "mask_rcnn_r_50_fpn_3x (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.mask_rcnn_R_50_FPN_3x"]], "mask_rcnn_x_101_32x8d_fpn_3x (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.mask_rcnn_X_101_32x8d_FPN_3x"]], "model_cfg_path (compressai_vision.model_wrappers.basewrapper property)": [[4, "compressai_vision.model_wrappers.BaseWrapper.model_cfg_path"]], "pretrained_weight_path (compressai_vision.model_wrappers.basewrapper property)": [[4, "compressai_vision.model_wrappers.BaseWrapper.pretrained_weight_path"]], "reset() (compressai_vision.model_wrappers.jde_1088x608 method)": [[4, "compressai_vision.model_wrappers.jde_1088x608.reset"]], "training (compressai_vision.model_wrappers.basewrapper attribute)": [[4, "compressai_vision.model_wrappers.BaseWrapper.training"]], "training (compressai_vision.model_wrappers.faster_rcnn_r_50_fpn_3x attribute)": [[4, "compressai_vision.model_wrappers.faster_rcnn_R_50_FPN_3x.training"]], "training (compressai_vision.model_wrappers.faster_rcnn_x_101_32x8d_fpn_3x attribute)": [[4, "compressai_vision.model_wrappers.faster_rcnn_X_101_32x8d_FPN_3x.training"]], "training (compressai_vision.model_wrappers.jde_1088x608 attribute)": [[4, "compressai_vision.model_wrappers.jde_1088x608.training"]], "training (compressai_vision.model_wrappers.mask_rcnn_r_50_fpn_3x attribute)": [[4, "compressai_vision.model_wrappers.mask_rcnn_R_50_FPN_3x.training"]], "training (compressai_vision.model_wrappers.mask_rcnn_x_101_32x8d_fpn_3x attribute)": [[4, "compressai_vision.model_wrappers.mask_rcnn_X_101_32x8d_FPN_3x.training"]], "training (compressai_vision.model_wrappers.yolox_darknet53 attribute)": [[4, "compressai_vision.model_wrappers.yolox_darknet53.training"]], "yolox_darknet53 (class in compressai_vision.model_wrappers)": [[4, "compressai_vision.model_wrappers.yolox_darknet53"]], "imageremoteinference (class in compressai_vision.pipelines.remote_inference)": [[6, "compressai_vision.pipelines.remote_inference.ImageRemoteInference"]], "videoremoteinference (class in compressai_vision.pipelines.remote_inference)": [[6, "compressai_vision.pipelines.remote_inference.VideoRemoteInference"]], "build_input_lists() (compressai_vision.pipelines.remote_inference.videoremoteinference method)": [[6, "compressai_vision.pipelines.remote_inference.VideoRemoteInference.build_input_lists"]], "compressai_vision.pipelines.remote_inference": [[6, "module-compressai_vision.pipelines.remote_inference"]], "training (compressai_vision.pipelines.remote_inference.imageremoteinference attribute)": [[6, "compressai_vision.pipelines.remote_inference.ImageRemoteInference.training"]], "training (compressai_vision.pipelines.remote_inference.videoremoteinference attribute)": [[6, "compressai_vision.pipelines.remote_inference.VideoRemoteInference.training"]], "imagesplitinference (class in compressai_vision.pipelines.split_inference)": [[7, "compressai_vision.pipelines.split_inference.ImageSplitInference"]], "videosplitinference (class in compressai_vision.pipelines.split_inference)": [[7, "compressai_vision.pipelines.split_inference.VideoSplitInference"]], "build_input_lists() (compressai_vision.pipelines.split_inference.videosplitinference method)": [[7, "compressai_vision.pipelines.split_inference.VideoSplitInference.build_input_lists"]], "compressai_vision.pipelines.split_inference": [[7, "module-compressai_vision.pipelines.split_inference"]], "training (compressai_vision.pipelines.split_inference.imagesplitinference attribute)": [[7, "compressai_vision.pipelines.split_inference.ImageSplitInference.training"]], "training (compressai_vision.pipelines.split_inference.videosplitinference attribute)": [[7, "compressai_vision.pipelines.split_inference.VideoSplitInference.training"]], "compressai_vision.registry": [[8, "module-compressai_vision.registry"]], "compressai_vision.registry.registry": [[8, "module-compressai_vision.registry.registry"]], "register_codec() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_codec"]], "register_datacatalog() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_datacatalog"]], "register_dataset() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_dataset"]], "register_evaluator() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_evaluator"]], "register_multask_codec() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_multask_codec"]], "register_pipeline() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_pipeline"]], "register_vision_model() (in module compressai_vision.registry.registry)": [[8, "compressai_vision.registry.registry.register_vision_model"]]}})