commands & parameters:

    --y                     non-interactive
    --debug                 debug verbosity (for some cases)

    manual                  shows this manual

    info                    shows info about your system

    mongo                   mongod management
        
        stop                kills all local mongod servers
        clean               like stop, but additionally, removes all
                            fiftyone data from the mongod servers

    mpeg-vcm-auto-import    auto-imports mpeg-vcm working group files
                            downloads necessary images from the internet
                            imports them to fiftyone, etc.
                            (combines download, convert-mpeg-to-oiv6, register, 
                            etc. commands, see below)

                            You should have these files in the running directory:

                            detection_validation_input_5k.lst
                            detection_validation_5k_bbox.csv
                            detection_validation_labels_5k.csv
                            segmentation_validation_input_5k.lst
                            segmentation_validation_bbox_5k.csv
                            segmentation_validation_labels_5k.csv
                            segmentation_validation_masks_5k.csv

    download                download an image set and register it to fiftyone.

        --dataset-name      name of the dataset.  Default: "open-images-v6".
        --lists             list files that define the subset of images to download.
        --split             typically "train" or "validation".  Default: None
                            (final dataset name is then for example "open-images-v6-validation"
        --dir               directory where the dataset (images, annotations, etc.) is downloaded
                            Default: $HOME/fiftyone/dataset-name

        example (downloads images corresponding the Common Test Conditions (CTC) of MPEG/VCM for
        the detection & segmentation tasks):

            compressai-vision download \\
            --lists=detection_validation_input_5k.lst,segmentation_validation_input_5k.lst \\
            --dataset-name=open-image-v6 --split=validation

    list                    list all datasets registered to fiftyone

    show                    show info about the dataset

        --dataset-name      dataset registered name
    

    register                register image set to fiftyone from local dir

        --dataset-name      dataset registered name
        --lists             lst files that define the subset of images to register
        --dir               source directory
        --type              fiftyone.types name.  Default: OpenImagesV6Dataset
                            typical values:

                                FiftyOneDataset
                                OpenImagesV6Dataset
                                ImageDirectory

        example (register converted MPEG/VCM files into fiftyone):

            compressai-vision register
                --dataset-name=mpeg_vcm-import
                --dir=~/somedir/mpeg_vcm-import

    deregister              de-register image set from fiftyone

        --dataset-name      name of the dataset, for example "open-image-v6-validation"

    dummy                   create & register a dummy dataset with just the first sample

        --dataset-name      name of the original dataset
                            name of the new dataset will be appended with "-dummy"

    clean                   remove temporary datasets.
                            detectron2-eval creates temporary clones of the dataset per each run.
                            These dataset are automatically cleaned up after detectron2_eval run.
                            If your run crashed, the temporary dataset might be left in the database
                            (you can see them with the list command where they appear with the name
                            "detectron-run-*".)

    detectron2-eval         evaluate model with detectron2 using OpenImageV6
                            evaluation protocol optionally with no (de)compression or
                            with compressai or vtm.

                            WARNING/TODO : currently works only for detections
                            (not for segmentations)

        --dataset-name      name of the fiftyone registered dataset
        --model             name of the detectron2 model
                            for example:
                            COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml
                            
                            It can also be a list of the models for multi-task scenario
                            for example:
                            COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml
                            COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml

        --eval-method       Evaluation method/protocol for mAP calculations: 
                            open-images or coco.  Default: open-images.
        --gt-field          Name of the ground truth field in the dataset.
                            Default: detections
        --output            outputfile, default: compressai-vision.json

        compression models:

        you can choose a compression model from compressai zoo, use vtm
        or a model you're currently developing.  If no model is chosen, then no (de)compression is
        done before passing the image to detectron

        --compressai-model-name     CompressAI model from the zoo, for example: bmshj2018_factorized
                                    can be a model name from the CompressAI model zoo (optional)
        --compression-model-path    load a custom model. Defines a path to directory with a custom development model.
                                    The directory should contain a properly formatted "model.py" file (optional)
        --compression-model-checkpoint
                                    a torch checkpoint file for loading the model state (.pth.tar file)
        --vtm                       use vtm (optional)
        --vtm_dir                   specify path to directory "VVCSoftware_VTM/bin", i.e. to the
                                    directory where there are executables "EncoderAppStatic" and
                                    "DecoderAppStatic".  If not specified, tries to use the
                                    environmental variable VTM_DIR
        --vtm_cfg                   path to vtm config file.  If not specified uses an internal
                                    default file.
        --vtm_cache                 specify a path to directory where the bitstreams are cached.
                                    The program saves bitstream to disk and tries to recycle the
                                    bitstreams saved earlier.
                                    Default: no caching.
                                    NOTE: the path is automatically appended with
                                    "scale/quality-parameter/" (see --scale)
        --qpars                     a quality parameters to be used with either compressai or vtm
        --scale                     ffmpeg scaling applied to the image as defined per VCM working group.
                                    values can be: 100 (original size), 75, 50, 25.
                                    0 = no scaling applied
        --ffmpeg                    specify ffmpeg command.  If not specified, uses "ffmpeg".
        --slice                     instead of using the complete dataset, just use a slice of the
                                    dataset: good for parallelizing the VTM encoder.
                                    Normal python slicing indexes are used.
        --debug                     enable debug verbosity
        --progressbar               show a fancy progressbar.  Default: false.  Nice for interactive runs.
        --progress                  show progress every n:th step, i.e. --progress=10 would print out
                                    progress every tenth step.  0: don't print anything. Default: 1.
                                    Nice for batch jobs.

        example 1 (calculate mAP):

            compressai-vision detectron2_eval
                --y --dataset-name=mpeg_vcm-detection \\
                --model=COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml

        example 2 (calculate mAP=mAP(bpp) with a model from CompressAI zoo):

            compressai-vision detectron2_eval --y --dataset-name=mpeg_vcm-detection \\
                --model=COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml \\
                --compressai=bmshj2018_factorized --qpars=1,2,3,4,5,6,7,8

        example 3 (calculate mAP=mAP(bpp) with a custom development model):

            compressai-vision detectron2_eval --y --dataset-name=mpeg_vcm-detection \\
                --model=COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml \\
                --modelpath=/path/to/directory --qpars=1

    vtm                 generate bitstream with the vtm video encoder
                        this is done also by the command detectron2_eval, but you
                        can do the bitstream generation step separately.
                        The following options are same as in "detectron2_eval" command:


        --dataset-name      name of the fiftyone registered dataset
        --output            outputfile, default: compressai-vision.json

        --vtm_dir           specify path to directory "VVCSoftware_VTM/bin", i.e. to the
                            directory where there are executables "EncoderAppStatic" and
                            "DecoderAppStatic".  If not specified, tries to use the
                             environmental variable VTM_DIR
        --vtm_cfg           path to vtm config file.  If not specified uses an internal
                            default file.
        --vtm_cache         specify a path to directory where the bitstreams are cached.
                            The program saves bitstream to disk and tries to recycle the
                            bitstreams saved earlier.
                            Default: no caching.
                            NOTE: the path is automatically appended with
                            "scale/quality-parameter/" (see --scale)
        --qpars             a quality parameters to be used with either compressai or vtm
        --scale             ffmpeg scaling applied to the image as defined per VCM working group.
                            values can be: 100 (original size), 75, 50, 25.
                            0 = no scaling applied
        --ffmpeg            specify ffmpeg command.  If not specified, uses "ffmpeg".
        --slice             instead of using the complete dataset, just use a slice of the
                            dataset: good for parallelizing the VTM encoder.
                            Normal python slicing indexes are used.
        --debug             enable debug verbosity
        --progressbar       show a fancy progressbar.  Default: false.  Nice for interactive runs.
        --progress          show progress every n:th step, i.e. --progress=10 would print out
                            progress every tenth step.  0: don't print anything. Default: 1.
                            Nice for batch jobs.

        --tags              pick certain images from the dataset/slice
                            for example: --tags=0001eeaf4aed83f9,000a1249af2bc5f0
                            the tags correspond to _open image ids_
        --keep              keep all intermediate files (for debugging)
        --check             simply reports which bitstream files are missing from the cache
                            if you enable this, no bitstream verification is done

        example 1:

            compressai-vision vtm
                --y --dataset-name=mpeg_vcm-detection --qpars=38,47 --vtm_cache=/path/to/dir

        example 2 (calculate bitstream for first 100 samples in the dataset):

            compressai-vision vtm
                --y --dataset-name=mpeg_vcm-detection --qpars=22 --vtm_cache=/path/to/dir --slice=0:100

    convert-mpeg-to-oiv6    convert the files specified in MPEG/VCM CTC into proper OpenImageV6
                            format & directory structure

        --lists             file listing necessary images, i.e.
                            "detection_validation_input_5k.lst" or
                            "segmentation_validation_input_5k.lst"
        --dir               a base OpenImageV6 dataset dir:
                            images are taken from "[dir]/data/" and masks from
                            "[dir]/labels/masks/"
        --target_dir        target directory directory for the converted format
        --label             image-level labels, i.e.
                            "detection_validation_labels_5k.csv" or
                            "segmentation_validation_labels_5k.csv"
        --bbox              bbox data, i.e.
                            "detection_validation_5k_bbox.csv" or
                            "segmentation_validation_bbox_5k.csv"
        --mask              segmentation masks,
                            i.e. "segmentation_validation_masks_5k.csv"
        example:

            compressai-vision convert_mpeg_to_oiv6
                --lists=detection_validation_input_5k.lst \\
                --bbox=detection_validation_5k_bbox.csv
                --label=detection_validation_labels_5k.csv \\
                --dir=~/fiftyone/open-image-v6/validation --target_dir=/path/to/dir

    import-custom           imports some custom datasets (both image and video datasets) into fiftyone

        --dataset-type      particular dataset in question.  Possible values are:
                            
                            sfu-hw-objects-v1
                            tvd_object_tracking_v1

        --dir               root dir of the dataset

    make-thumbnails         add "thumbnail" videos that are compatible with browser-based applications to the dataset.
                            this way you will have "side-data" video for visualization in the fiftyone app
                            while still performing training & evaluation with the original data
                            (that might not visualize correctly in the webapp)

        --dataset-name      name of the dataset
        --force             force encoding even if the "thumbnail" videos already existed

    metrics-eval                        evaluate image quality of reconstructed images

            --dataset-name              name of the dataset

            compressai-zoo arguments:
            --compressai-model-name     name of an existing model in compressai-zoo. Example: 'cheng2020-attn'
            --compression-model-path    path to a directory containing model.py for custom development model

            vtm arguments:
            --vtm                       To enable vtm codec. default: False
            --vtm_dir                   path to directory with executables EncoderAppStatic & DecoderAppStatic
            --vtm_cfg                   vtm config file. Example: 'encoder_intra_vtm.cfg'
            --vtm_cache                 directory to cache vtm bitstreams

            optional arguments:
            --Output            outputfile name
                                Default: compressai-vision.json
            --qpars             quality parameters for compressai model or vtm. For compressai-zoo model, it should be integer
                                1-8. For VTM, it should be integer from 0-51.
                                Example: 1,2,3,4,5,6,7,8
            --scale             image scaling as per VCM working group docs. 
                                Default: 100
            --ffmpeg            path of ffmpeg executable. 
                                Default: ffmpeg
            --slice             use a dataset slice instead of the complete dataset.
                                Example: 0:2 for the first two images
            --progressbar       show fancy progressbar. 
                                Default: False
            --progress          Print progress this often

    plot                        plot the json result of detectron2-eval and metrics-eval as mAP-bpp curves

            --dirs              list of directories with json files, produced by 
                                detectron2-eval subcommand

                                Each directory corresponds to an evaluation of a certain model
                                done with detectron2-eval: each directory contains a list of json files, 
                                produced by the subcommand detectron2-eval.

                                Within one directory, you typically have json files, 
                                produced in a parallel run for
                                each quality point, for example: 1.json, 2.json, ..

                                Or you can have a json files with several quality point results 
                                in each file, say: 1_2_3.json, 4_5.json, ..

                                The program knows how to combine these files.

            --symbols           list of matplotlib symbols for each plot,
                                for example: o--k,-g,*:r (optional)
            --names             list of names to be included into the plot,
                                for example: vtm,mymodel,mymodel2 (optional)
            --eval              mAP value without (de)compress and maplotlib symbol,
                                for example: 0.792,--c 
            --csv               instead of plot, dump json results in csv format

        instructions:

            The compressai-vision detectron2-eval command has produced you json output files
            to a certain directory (say, into "model1_results/")

            In a single json file you can have multiple (bpp, mAP) results (for
            each quality parameter)

            You can also have several json files, each containing just one or more
            (bpp, mAP) results (say, if you have parallelized compressai-vision run
            over quality parameters)

            This script handles both situations automatically, you just need to
            provide the directory name(s)

            Suppose you want to plot two (bpp, mAP) curves from two models
            (results are in "model1_results" and "model2_results"), do this:

            compressai-vision plot --dirs=model1_results,model2_results \\
            --symbols=o--r,x-b --dataset-names=model1,model2 \\
            --eval=0.792,--c




NOTE 1: your normal workflow would be: download, convert_mpeg_to_oiv6, register, detectron2_eval
the first three steps can be dealt with the compress-mpeg-vcm-auto-import command

NOTE 2: for vtm, you would typically produce bitstream with the vtm command and only after that,
launch detectron2-eval.  Be sure not to send several parallel (batch) jobs using the same dataset slices.
