diff --git a/detectron2/modeling/backbone/fpn.py b/detectron2/modeling/backbone/fpn.py
index d0bdfc9..ee16926 100644
--- a/detectron2/modeling/backbone/fpn.py
+++ b/detectron2/modeling/backbone/fpn.py
@@ -110,7 +110,7 @@ class FPN(Backbone):
     def size_divisibility(self):
         return self._size_divisibility
 
-    def forward(self, x):
+    def forward(self, x, no_bottom_up=False):
         """
         Args:
             input (dict[str->Tensor]): mapping feature map name (e.g., "res5") to
@@ -123,7 +123,13 @@ class FPN(Backbone):
                 paper convention: "p<stage>", where stage has stride = 2 ** stage e.g.,
                 ["p2", "p3", ..., "p6"].
         """
-        bottom_up_features = self.bottom_up(x)
+
+        if no_bottom_up is False:
+            bottom_up_features = self.bottom_up(x)
+        else:
+            assert isinstance(x, dict)
+            bottom_up_features = x
+
         results = []
         prev_features = self.lateral_convs[0](bottom_up_features[self.in_features[-1]])
         results.append(self.output_convs[0](prev_features))
@@ -153,6 +159,49 @@ class FPN(Backbone):
         assert len(self._out_features) == len(results)
         return {f: res for f, res in zip(self._out_features, results)}
 
+    def forward_after_c2(self, x):
+        """
+        Args:
+            input (dict[str->Tensor]): mapping feature map name (e.g., "{c2, c3, c4, c5}") to
+                feature map tensor for each feature level in high to low resolution order.
+
+        Returns:
+            dict[str->Tensor]:
+                mapping from feature map name to FPN feature map tensor
+                in high to low resolution order. Returned feature names follow the FPN
+                paper convention: "p<stage>", where stage has stride = 2 ** stage e.g.,
+                ["p2", "p3", ..., "p6"].
+        """
+
+        in_cfeatures = ["c2", "c3", "c4", "c5"]
+
+        assert isinstance(x, dict)
+        assert list(x.keys()) == in_cfeatures
+        lateral_features = x
+        prev_features = lateral_features["c5"]
+
+        results = []
+        results.append(self.output_convs[0](prev_features))
+
+        # Reverse feature maps into top-down order (from low to high resolution)
+        for idx, output_conv in enumerate(self.output_convs):
+            # Slicing of ModuleList is not supported https://github.com/pytorch/pytorch/issues/47336
+            # Therefore we loop over all modules but skip the first one
+            if idx > 0:
+                fkey = in_cfeatures[-idx - 1]
+                top_down_features = F.interpolate(prev_features, scale_factor=2.0, mode="nearest")
+                prev_features = lateral_features[fkey] + top_down_features
+                if self._fuse_type == "avg":
+                    prev_features /= 2
+                results.insert(0, output_conv(prev_features))
+
+        if self.top_block is not None:
+            top_block_in_feature = results[self._out_features.index(self.top_block.in_feature)]
+            results.extend(self.top_block(top_block_in_feature))
+        assert len(self._out_features) == len(results)
+
+        return {f: res for f, res in zip(self._out_features, results)}
+
     def output_shape(self):
         return {
             name: ShapeSpec(
