

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>7. Importing and Using Video &#8212; CompressAI Vision</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/cli_tutorial_7';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Setup</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Library API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../codec/index.html">compressai_vision.codecs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluators/index.html">compressai_vision.evaluators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pipelines/index.html">compressai_vision.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_wrappers/index.html">compressai_vision.model_wrappers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Supported datasets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://github.com/InterDigitalInc/CompressAI-Vision">Github repository</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/InterDigitalInc/CompressAI-Vision" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorials/cli_tutorial_7.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>7. Importing and Using Video</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="importing-and-using-video">
<h1>7. Importing and Using Video<a class="headerlink" href="#importing-and-using-video" title="Permalink to this heading">#</a></h1>
<p id="cli-tutorial-7">In this tutorial you will learn how to:</p>
<ul class="simple">
<li><p>Download and register video datasets</p></li>
<li><p>Convert and import the <code class="docutils literal notranslate"><span class="pre">sfu-hw-objects-v1</span></code> raw custom video data
format</p></li>
<li><p>Play around with video datasets, visualize frames and detection
results</p></li>
<li><p>Evaluate a video dataset</p></li>
</ul>
<p>In chapter 2 of this tutorial you learned how to download and register
datasets to fiftyone with the <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">register</span></code> command.</p>
<p>Exactly the same command works for video datasets:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>compressai-vision<span class="w"> </span>download<span class="w"> </span>--dataset-name<span class="o">=</span>quickstart-video<span class="w"> </span>--y
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>importing fiftyone
fiftyone imported

WARNING: downloading ALL images.  You might want to use the --lists option to download only certain images
Using list files:     None
Number of images:     ?
Database name   :     quickstart-video
Subname/split   :     None
Target dir      :     None

Dataset already downloaded
Loading existing dataset &#39;quickstart-video&#39;. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use
</pre></div>
</div>
<p>If you have your video dataset arranged in one of the standard <a class="reference external" href="https://voxel51.com/docs/fiftyone/api/fiftyone.types.dataset_types.html">video
data formats supported by
fiftyone</a>,
you’re good to go.</p>
<p>Manipulating and visualizing video datasets from python works a bit
different to image datasets. For this, please see the end of this
tutorial.</p>
<p>Next we will import a raw custom dataset, namely the
<a class="reference external" href="http://dx.doi.org/10.17632/hwm673bv4m.1">sfu-hw-objects-v1</a> into
fiftyone.</p>
<p>This format consists raw YUV video files and annotations. Let’s see how
the folder structure is roughly organized. We’ll be using in this
tutorial a “mock” version of the dataset with only two video classes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tree<span class="w"> </span><span class="o">{</span>path_to_sfu_hw_objects_v1<span class="o">}</span><span class="w"> </span>--filelimit<span class="o">=</span><span class="m">10</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cat
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1
├── ClassC
│   ├── Annotations
│   │   └── BasketballDrill [502 entries exceeds filelimit, not opening dir]
│   └── BasketballDrill_832x480_50Hz_8bit_P420.yuv
└── ClassX
    ├── Annotations
    │   └── BasketballDrill
    │       ├── BasketballDrill_832x480_50_seq_001.txt
    │       ├── BasketballDrill_832x480_50_seq_002.txt
    │       ├── BasketballDrill_832x480_50_seq_003.txt
    │       ├── BasketballDrill_832x480_50_seq_004.txt
    │       └── BasketballDrill_832x480_object.list
    └── BasketballDrill_832x480_50Hz_8bit_P420.yuv -&gt; /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/BasketballDrill_832x480_50Hz_8bit_P420.yuv

6 directories, 7 files
</pre></div>
</div>
<p>Importing mpeg-vcom custom datasets (for more info see Dataset section
of the documentation) can be done with <code class="docutils literal notranslate"><span class="pre">import-custom</span></code> command. For
<code class="docutils literal notranslate"><span class="pre">sfu-hw-objects-v1</span></code> it also converts on-the-fly the raw YUV images
into proper video format:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>compressai-vision<span class="w"> </span>import-custom<span class="w"> </span>--dataset-type<span class="o">=</span>sfu-hw-objects-v1<span class="w"> </span>--dir<span class="o">={</span>path_to_sfu_hw_objects_v1<span class="o">}</span><span class="w"> </span>--y
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>importing fiftyone
fiftyone imported
WARNING: dataset sfu-hw-objects-v1 already exists: will delete and rewrite

Importing a custom video format into fiftyone

Dataset type           :  sfu-hw-objects-v1
Dataset root directory :  /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1

finding .yuv files from /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1
ffmpeg -y -f rawvideo -pixel_format yuv420p -video_size 832x480 -i /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/BasketballDrill_832x480_50Hz_8bit_P420.yuv -an -c:v h264 -q 0 /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/Annotations/BasketballDrill/video.mp4
ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers
  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)
  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared
  libavutil      56. 31.100 / 56. 31.100
  libavcodec     58. 54.100 / 58. 54.100
  libavformat    58. 29.100 / 58. 29.100
  libavdevice    58.  8.100 / 58.  8.100
  libavfilter     7. 57.100 /  7. 57.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  5.100 /  5.  5.100
  libswresample   3.  5.100 /  3.  5.100
  libpostproc    55.  5.100 / 55.  5.100
[0;35m[rawvideo @ 0x561a0d3c17c0] [0m[0;33mEstimating duration from bitrate, this may be inaccurate
[0mInput #0, rawvideo, from &#39;/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/BasketballDrill_832x480_50Hz_8bit_P420.yuv&#39;:
  Duration: 00:00:20.04, start: 0.000000, bitrate: 119808 kb/s
    Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 832x480, 119808 kb/s, 25 tbr, 25 tbn, 25 tbc
Stream mapping:
  Stream #0:0 -&gt; #0:0 (rawvideo (native) -&gt; h264 (libx264))
Press [q] to stop, [?] for help
[1;36m[libx264 @ 0x561a0d3cf300] [0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2
[1;36m[libx264 @ 0x561a0d3cf300] [0mprofile High, level 3.0
[1;36m[libx264 @ 0x561a0d3cf300] [0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00
Output #0, mp4, to &#39;/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/Annotations/BasketballDrill/video.mp4&#39;:
  Metadata:
    encoder         : Lavf58.29.100
    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 832x480, q=-1--1, 25 fps, 12800 tbn, 25 tbc
    Metadata:
      encoder         : Lavc58.54.100 libx264
    Side data:
      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1
frame=  501 fps=143 q=-1.0 Lsize=    3979kB time=00:00:19.92 bitrate=1636.2kbits/s speed=5.67x
video:3972kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.169325%
[1;36m[libx264 @ 0x561a0d3cf300] [0mframe I:3     Avg QP:22.61  size: 56539
[1;36m[libx264 @ 0x561a0d3cf300] [0mframe P:126   Avg QP:24.67  size: 17479
[1;36m[libx264 @ 0x561a0d3cf300] [0mframe B:372   Avg QP:28.66  size:  4556
[1;36m[libx264 @ 0x561a0d3cf300] [0mconsecutive B-frames:  1.0%  0.0%  0.0% 99.0%
[1;36m[libx264 @ 0x561a0d3cf300] [0mmb I  I16..4: 13.3% 37.2% 49.4%
[1;36m[libx264 @ 0x561a0d3cf300] [0mmb P  I16..4:  0.1% 11.2%  6.3%  P16..4: 42.9% 16.1% 11.6%  0.0%  0.0%    skip:11.7%
[1;36m[libx264 @ 0x561a0d3cf300] [0mmb B  I16..4:  0.0%  0.7%  0.4%  B16..8: 35.6%  9.2%  3.6%  direct: 3.0%  skip:47.6%  L0:43.7% L1:43.7% BI:12.7%
[1;36m[libx264 @ 0x561a0d3cf300] [0m8x8 transform intra:60.9% inter:67.7%
[1;36m[libx264 @ 0x561a0d3cf300] [0mcoded y,uvDC,uvAC intra: 87.9% 88.2% 66.7% inter: 22.5% 18.1% 4.7%
[1;36m[libx264 @ 0x561a0d3cf300] [0mi16 v,h,dc,p: 57% 13%  8% 22%
[1;36m[libx264 @ 0x561a0d3cf300] [0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 11%  8%  9%  7% 19% 17% 10%  9%  9%
[1;36m[libx264 @ 0x561a0d3cf300] [0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14%  9% 13%  7% 19% 15%  8%  7%  6%
[1;36m[libx264 @ 0x561a0d3cf300] [0mi8c dc,h,v,p: 48% 17% 22% 13%
[1;36m[libx264 @ 0x561a0d3cf300] [0mWeighted P-Frames: Y:0.0% UV:0.0%
[1;36m[libx264 @ 0x561a0d3cf300] [0mref P L0: 44.5% 27.1% 14.9% 13.6%
[1;36m[libx264 @ 0x561a0d3cf300] [0mref B L0: 85.6% 10.0%  4.4%
[1;36m[libx264 @ 0x561a0d3cf300] [0mref B L1: 94.4%  5.6%
[1;36m[libx264 @ 0x561a0d3cf300] [0mkb/s:1623.41
ffmpeg -y -f rawvideo -pixel_format yuv420p -video_size 832x480 -i /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/BasketballDrill_832x480_50Hz_8bit_P420.yuv -an -c:v h264 -q 0 /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/Annotations/BasketballDrill/video.mp4
ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers
  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)
  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared
  libavutil      56. 31.100 / 56. 31.100
  libavcodec     58. 54.100 / 58. 54.100
  libavformat    58. 29.100 / 58. 29.100
  libavdevice    58.  8.100 / 58.  8.100
  libavfilter     7. 57.100 /  7. 57.100
  libavresample   4.  0.  0 /  4.  0.  0
  libswscale      5.  5.100 /  5.  5.100
  libswresample   3.  5.100 /  3.  5.100
  libpostproc    55.  5.100 / 55.  5.100
[0;35m[rawvideo @ 0x559c0f4467c0] [0m[0;33mEstimating duration from bitrate, this may be inaccurate
[0mInput #0, rawvideo, from &#39;/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/BasketballDrill_832x480_50Hz_8bit_P420.yuv&#39;:
  Duration: 00:00:20.04, start: 0.000000, bitrate: 119808 kb/s
    Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 832x480, 119808 kb/s, 25 tbr, 25 tbn, 25 tbc
Stream mapping:
  Stream #0:0 -&gt; #0:0 (rawvideo (native) -&gt; h264 (libx264))
Press [q] to stop, [?] for help
[1;36m[libx264 @ 0x559c0f454300] [0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2
[1;36m[libx264 @ 0x559c0f454300] [0mprofile High, level 3.0
[1;36m[libx264 @ 0x559c0f454300] [0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00
Output #0, mp4, to &#39;/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/Annotations/BasketballDrill/video.mp4&#39;:
  Metadata:
    encoder         : Lavf58.29.100
    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 832x480, q=-1--1, 25 fps, 12800 tbn, 25 tbc
    Metadata:
      encoder         : Lavc58.54.100 libx264
    Side data:
      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1
frame=  501 fps=131 q=-1.0 Lsize=    3979kB time=00:00:19.92 bitrate=1636.2kbits/s speed= 5.2x
video:3972kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.169325%
[1;36m[libx264 @ 0x559c0f454300] [0mframe I:3     Avg QP:22.61  size: 56539
[1;36m[libx264 @ 0x559c0f454300] [0mframe P:126   Avg QP:24.67  size: 17479
[1;36m[libx264 @ 0x559c0f454300] [0mframe B:372   Avg QP:28.66  size:  4556
[1;36m[libx264 @ 0x559c0f454300] [0mconsecutive B-frames:  1.0%  0.0%  0.0% 99.0%
[1;36m[libx264 @ 0x559c0f454300] [0mmb I  I16..4: 13.3% 37.2% 49.4%
[1;36m[libx264 @ 0x559c0f454300] [0mmb P  I16..4:  0.1% 11.2%  6.3%  P16..4: 42.9% 16.1% 11.6%  0.0%  0.0%    skip:11.7%
[1;36m[libx264 @ 0x559c0f454300] [0mmb B  I16..4:  0.0%  0.7%  0.4%  B16..8: 35.6%  9.2%  3.6%  direct: 3.0%  skip:47.6%  L0:43.7% L1:43.7% BI:12.7%
[1;36m[libx264 @ 0x559c0f454300] [0m8x8 transform intra:60.9% inter:67.7%
[1;36m[libx264 @ 0x559c0f454300] [0mcoded y,uvDC,uvAC intra: 87.9% 88.2% 66.7% inter: 22.5% 18.1% 4.7%
[1;36m[libx264 @ 0x559c0f454300] [0mi16 v,h,dc,p: 57% 13%  8% 22%
[1;36m[libx264 @ 0x559c0f454300] [0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 11%  8%  9%  7% 19% 17% 10%  9%  9%
[1;36m[libx264 @ 0x559c0f454300] [0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14%  9% 13%  7% 19% 15%  8%  7%  6%
[1;36m[libx264 @ 0x559c0f454300] [0mi8c dc,h,v,p: 48% 17% 22% 13%
[1;36m[libx264 @ 0x559c0f454300] [0mWeighted P-Frames: Y:0.0% UV:0.0%
[1;36m[libx264 @ 0x559c0f454300] [0mref P L0: 44.5% 27.1% 14.9% 13.6%
[1;36m[libx264 @ 0x559c0f454300] [0mref B L0: 85.6% 10.0%  4.4%
[1;36m[libx264 @ 0x559c0f454300] [0mref B L1: 94.4%  5.6%
[1;36m[libx264 @ 0x559c0f454300] [0mkb/s:1623.41
video conversion done
searching for /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/Class*
Dataset sfu-hw-objects-v1 exists.  Will remove it first
Dataset sfu-hw-objects-v1 created

In class directory /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC
searching for /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/Annotations/*
--&gt; registering video /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/Annotations/BasketballDrill/video.mp4
--&gt; registered new video sample: ClassC BasketballDrill with 500 frames

In class directory /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX
searching for /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/Annotations/*
--&gt; registering video /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/Annotations/BasketballDrill/video.mp4
--&gt; registered new video sample: ClassX BasketballDrill with 4 frames

Dataset saved
</pre></div>
</div>
<p>In order to demonstrate how video datasets are used, let’s continue in
python notebook:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import cv2
import matplotlib.pyplot as plt
import fiftyone as fo
from fiftyone import ViewField as F
from math import floor
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset=fo.load_dataset(&quot;sfu-hw-objects-v1&quot;)
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Name</span><span class="p">:</span>        <span class="n">sfu</span><span class="o">-</span><span class="n">hw</span><span class="o">-</span><span class="n">objects</span><span class="o">-</span><span class="n">v1</span>
<span class="n">Media</span> <span class="nb">type</span><span class="p">:</span>  <span class="n">video</span>
<span class="n">Num</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">Persistent</span><span class="p">:</span>  <span class="kc">True</span>
<span class="n">Tags</span><span class="p">:</span>        <span class="p">[]</span>
<span class="n">Sample</span> <span class="n">fields</span><span class="p">:</span>
    <span class="nb">id</span><span class="p">:</span>         <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">ObjectIdField</span>
    <span class="n">filepath</span><span class="p">:</span>   <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span>
    <span class="n">tags</span><span class="p">:</span>       <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">ListField</span><span class="p">(</span><span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span><span class="p">)</span>
    <span class="n">metadata</span><span class="p">:</span>   <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">EmbeddedDocumentField</span><span class="p">(</span><span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">VideoMetadata</span><span class="p">)</span>
    <span class="n">media_type</span><span class="p">:</span> <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span>
    <span class="n">class_tag</span><span class="p">:</span>  <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span>
    <span class="n">name_tag</span><span class="p">:</span>   <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span>
    <span class="n">custom_id</span><span class="p">:</span>  <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">StringField</span>
<span class="n">Frame</span> <span class="n">fields</span><span class="p">:</span>
    <span class="nb">id</span><span class="p">:</span>           <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">ObjectIdField</span>
    <span class="n">frame_number</span><span class="p">:</span> <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">FrameNumberField</span>
    <span class="n">detections</span><span class="p">:</span>   <span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">EmbeddedDocumentField</span><span class="p">(</span><span class="n">fiftyone</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">Detections</span><span class="p">)</span>
</pre></div>
</div>
<p>In contrast to image datasets where each sample was an image, now a
sample corresponds to a video:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset.first()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">Sample</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe83dd3cdcdcd97f0f64&#39;</span><span class="p">,</span>
    <span class="s1">&#39;media_type&#39;</span><span class="p">:</span> <span class="s1">&#39;video&#39;</span><span class="p">,</span>
    <span class="s1">&#39;filepath&#39;</span><span class="p">:</span> <span class="s1">&#39;/home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassC/Annotations/BasketballDrill/video.mp4&#39;</span><span class="p">,</span>
    <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
    <span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s1">&#39;class_tag&#39;</span><span class="p">:</span> <span class="s1">&#39;ClassC&#39;</span><span class="p">,</span>
    <span class="s1">&#39;name_tag&#39;</span><span class="p">:</span> <span class="s1">&#39;BasketballDrill&#39;</span><span class="p">,</span>
    <span class="s1">&#39;custom_id&#39;</span><span class="p">:</span> <span class="s1">&#39;ClassC_BasketballDrill&#39;</span><span class="p">,</span>
    <span class="s1">&#39;frames&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">Frames</span><span class="p">:</span> <span class="mi">500</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>There is a reference to the video file and a <code class="docutils literal notranslate"><span class="pre">Frames</span></code> object,
encapsulating ground truths etc. data for each and every frame. For
<code class="docutils literal notranslate"><span class="pre">sfu-hw-objects-v1</span></code> in particular, <code class="docutils literal notranslate"><span class="pre">class_tag</span></code> corresponds to the
class directories (ClassA, ClassB, etc.), while <code class="docutils literal notranslate"><span class="pre">name_tag</span></code> to the
video descriptive names (BasketballDrill, Traffic, PeopleOnStreeet,
etc.). Let’s pick a certain video sample:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sample = dataset[ (F(&quot;name_tag&quot;) == &quot;BasketballDrill&quot;) &amp; (F(&quot;class_tag&quot;) == &quot;ClassC&quot;) ].first()
</pre></div>
</div>
<p>Take a look at the first frame ground truth detections (note that frame
indices start from 1):</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sample.frames[1]
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">FrameView</span><span class="p">:</span> <span class="p">{</span>
    <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe832c777ac161910233&#39;</span><span class="p">,</span>
    <span class="s1">&#39;frame_number&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;detections&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">Detections</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;detections&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb3&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span><span class="mf">0.2525</span><span class="p">,</span> <span class="mf">0.8288</span><span class="p">,</span> <span class="mf">0.1812</span><span class="p">,</span> <span class="mf">0.1678</span><span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb4&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span><span class="mf">0.63635</span><span class="p">,</span> <span class="mf">0.00874999999999998</span><span class="p">,</span> <span class="mf">0.1207</span><span class="p">,</span> <span class="mf">0.3149</span><span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb5&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.30820000000000003</span><span class="p">,</span>
                    <span class="mf">0.32125000000000004</span><span class="p">,</span>
                    <span class="mf">0.1828</span><span class="p">,</span>
                    <span class="mf">0.5125</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb6&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span><span class="mf">0.5392</span><span class="p">,</span> <span class="mf">0.7257</span><span class="p">,</span> <span class="mf">0.2042</span><span class="p">,</span> <span class="mf">0.2812</span><span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb7&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;sports ball&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.045313000000000006</span><span class="p">,</span>
                    <span class="mf">0.37777800000000006</span><span class="p">,</span>
                    <span class="mf">0.160156</span><span class="p">,</span>
                    <span class="mf">0.2375</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb8&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;sports ball&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.142969</span><span class="p">,</span>
                    <span class="mf">0.020833499999999998</span><span class="p">,</span>
                    <span class="mf">0.03125</span><span class="p">,</span>
                    <span class="mf">0.061111</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbb9&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;chair&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.11015650000000002</span><span class="p">,</span>
                    <span class="mf">0.002777500000000002</span><span class="p">,</span>
                    <span class="mf">0.096875</span><span class="p">,</span>
                    <span class="mf">0.176389</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbba&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;chair&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.18125000000000002</span><span class="p">,</span>
                    <span class="mf">0.0041665000000000035</span><span class="p">,</span>
                    <span class="mf">0.089062</span><span class="p">,</span>
                    <span class="mf">0.141667</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
            <span class="o">&lt;</span><span class="n">Detection</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;636cfe82dd3cdcdcd97efbbb&#39;</span><span class="p">,</span>
                <span class="s1">&#39;attributes&#39;</span><span class="p">:</span> <span class="n">BaseDict</span><span class="p">({}),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([]),</span>
                <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;chair&#39;</span><span class="p">,</span>
                <span class="s1">&#39;bounding_box&#39;</span><span class="p">:</span> <span class="n">BaseList</span><span class="p">([</span>
                    <span class="mf">0.2460935</span><span class="p">,</span>
                    <span class="mf">0.0013889999999999944</span><span class="p">,</span>
                    <span class="mf">0.082031</span><span class="p">,</span>
                    <span class="mf">0.115278</span><span class="p">,</span>
                <span class="p">]),</span>
                <span class="s1">&#39;mask&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="p">]),</span>
    <span class="p">}</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Start reading the video file with OpenCV:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>vid=cv2.VideoCapture(sample.filepath)
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(&quot;number of frames:&quot;,int(vid.get(cv2.CAP_PROP_FRAME_COUNT)))
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>number of frames: 501
</pre></div>
</div>
<p>Let’s define a small helper function:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def draw_detections(sample: fo.Sample, vid: cv2.VideoCapture, nframe: int):
    nmax=int(vid.get(cv2.CAP_PROP_FRAME_COUNT))
    if nframe &gt; nmax:
        raise AssertionError(&quot;max frame is &quot; + str(nmax))
    ok = vid.set(cv2.CAP_PROP_POS_FRAMES, nframe-1)
    if not ok:
        raise AssertionError(&quot;seek failed&quot;)
    ok, arr = vid.read() # BGR image in arr
    if not ok:
        raise AssertionError(&quot;no image&quot;)
    for detection in sample.frames[nframe].detections.detections:
        x0, y0, w, h = detection.bounding_box # rel coords
        x1, y1, x2, y2 = floor(x0*arr.shape[1]), floor(y0*arr.shape[0]), floor((x0+w)*arr.shape[1]), floor((y0+h)*arr.shape[0])
        arr=cv2.rectangle(arr, (x1, y1), (x2, y2), (255, 0, 0), 5)
    return arr
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>img=draw_detections(sample, vid, 200)
img_ = img[:,:,::-1] # BGR -&gt; RGB
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.imshow(img_)
vid.release()
</pre></div>
</div>
<img alt="../_images/cli_tutorial_7_nb_22_0.png" src="../_images/cli_tutorial_7_nb_22_0.png" />
<p>For now, let’s get back to terminal command line.</p>
<p>Everything that you learned for image datasets, applies for video
datasets as well: <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">import-custom</span></code> can be used to
import mpeg-vcm datasets. <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">app</span></code> can be used to
visualize video datasets interactively. For visualizing videos in the
fiftyone app a small tip: when you play video and then stop it, the
bboxes might seem to be off. However, when you click the timeline
(i.e. seek) to a certain point, they match the video again (seems to be
a small bug in the fiftyone video visualization app).</p>
<p>When using the fiftyone app, there is a small catch though. Web-browsers
are picky on the type of video they can play. For some video datasets,
in order to view them in the app, you need to create separate
“side-data” videos for visualization. These you can generate these
automagically with the <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">make-thumbnails</span></code> command.
Note that <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">import-custom</span></code> generates you these
thumbnails on-the-go when you import new video sets. Switching between
the main video and “side-data” video is demoed in <a class="reference external" href="https://voxel51.com/docs/fiftyone/_images/app-multiple-media-fields.gif">this
animation</a></p>
<p>In chapters 3 and 4 you learned how to evaluate models (in serial and
parallel) with the <code class="docutils literal notranslate"><span class="pre">compressai-vision</span> <span class="pre">detectron2-eval</span></code> command.</p>
<p>The same command can be used to evaluate video datasets as well. Here
the parameter <code class="docutils literal notranslate"><span class="pre">--slice</span></code> refers to videos, not individual image (as
usual, for a production run, you would remove the <code class="docutils literal notranslate"><span class="pre">--slice</span></code>
parameter):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>compressai-vision<span class="w"> </span>detectron2-eval<span class="w"> </span>--y<span class="w"> </span>--dataset-name<span class="o">=</span>sfu-hw-objects-v1<span class="w"> </span><span class="se">\</span>
--slice<span class="o">=</span><span class="m">1</span>:2<span class="w"> </span><span class="se">\</span>
--scale<span class="o">=</span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
--progressbar<span class="w"> </span><span class="se">\</span>
--output<span class="o">=</span>detectron2_test.json<span class="w"> </span><span class="se">\</span>
--model<span class="o">=</span>COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>importing fiftyone
fiftyone imported
WARNING: using a dataset slice instead of full dataset: SURE YOU WANT THIS?

Using dataset          : sfu-hw-objects-v1
Dataset media type     : video
Dataset tmp clone      : detectron-run-sampsa-sfu-hw-objects-v1-2022-11-10-15-37-24-746313
Image scaling          : 100
WARNING: Using slice   : 1:2
Number of samples      : 1
Torch device           : cpu
Detectron2 model       : COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml
Model was trained with : coco_2017_train
** Evaluation without Encoding/Decoding **
Ground truth data field name
                       : detections
Eval. results will be saved to datafield
                       : detectron-predictions
Evaluation protocol    : open-images
Progressbar            : True
WARNING: progressbar enabled --&gt; disabling normal progress print
Print progress         : 0
Output file            : detectron2_test.json
Peek model classes     :
[&#39;airplane&#39;, &#39;apple&#39;, &#39;backpack&#39;, &#39;banana&#39;, &#39;baseball bat&#39;] ...
Peek dataset classes   :
[&#39;chair&#39;, &#39;person&#39;, &#39;sports ball&#39;] ...
cloning dataset sfu-hw-objects-v1 to detectron-run-sampsa-sfu-hw-objects-v1-2022-11-10-15-37-24-746313
instantiating Detectron2 predictor
USING VIDEO /home/sampsa/silo/interdigital/mock/SFU-HW-Objects-v1/ClassX/Annotations/BasketballDrill/video.mp4
seeking to 2
/home/sampsa/silo/interdigital/venv_all/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
 100% |███████████████████████████████████████████████████████████████████| 4/4 Evaluating detections...
 100% |███████████| 1/1 [71.8ms elapsed, 0s remaining, 13.9 samples/s]
deleting tmp database detectron-run-sampsa-sfu-hw-objects-v1-2022-11-10-15-37-24-746313

Done!
</pre></div>
</div>
<p>Take a look at the results:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cat detectron2_test.json
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  &quot;dataset&quot;: &quot;sfu-hw-objects-v1&quot;,
  &quot;gt_field&quot;: &quot;detections&quot;,
  &quot;tmp datasetname&quot;: &quot;detectron-run-sampsa-sfu-hw-objects-v1-2022-11-10-15-37-24-746313&quot;,
  &quot;slice&quot;: &quot;1:2&quot;,
  &quot;model&quot;: &quot;COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml&quot;,
  &quot;codec&quot;: &quot;&quot;,
  &quot;qpars&quot;: null,
  &quot;bpp&quot;: [
    null
  ],
  &quot;map&quot;: [
    0.5370370370370371
  ],
  &quot;map_per_class&quot;: [
    {
      &quot;chair&quot;: 0.1111111111111111,
      &quot;person&quot;: 1.0,
      &quot;sports ball&quot;: 0.5
    }
  ]
}
</pre></div>
</div>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By InterDigital Communications, Inc.
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, InterDigital Communications, Inc..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>